{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chclau/MIF_Gen/blob/master/square_tr_cnn_v3_works.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDb1GHBxwLL7",
        "colab_type": "code",
        "outputId": "c4cbe77f-f6a7-41cd-fbbb-93170cc96503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import shuffle\n",
        "\n",
        "\n",
        "# DML CNN section\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Import TensorFlow and TensorFlow Datasets\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# Generate squares and triangles training database\n",
        "img_size = 12;\n",
        "train_size = 500;\n",
        "test_size  = np.int8(train_size/5);\n",
        "sq_train   = np.zeros((img_size, img_size, train_size));\n",
        "tr_train   = np.zeros((img_size, img_size, train_size));\n",
        "sq_test    = np.zeros((img_size, img_size, train_size));\n",
        "tr_test    = np.zeros((img_size, img_size, train_size));\n",
        "\n",
        "for k in range(train_size):\n",
        "  x0 = np.int8(3 * np.random.random_sample())+1;   # random origin x coord\n",
        "  y0 = np.int8(3 * np.random.random_sample())+1;   # random origin y coord\n",
        "  w = np.int8(img_size/3 * np.random.random_sample()+img_size/3);   # random size\n",
        "\n",
        "  # square\n",
        "  for i in range(w):\n",
        "    for j in range(w):\n",
        "      sq_train[y0+i, x0+j, k] = 1;\n",
        "  \n",
        "  # triangle      \n",
        "  for i in range(w):\n",
        "    for j in range(i):\n",
        "      tr_train[y0+i, x0+j, k] = 1;\n",
        "  \n",
        "     \n",
        "# Generate squares and triangles validation database\n",
        "for k in range(test_size):\n",
        "  x0 = np.int8(3 * np.random.random_sample()+img_size/4);   # random origin x coord for test images\n",
        "  y0 = np.int8(3 * np.random.random_sample()+img_size/4);   # random origin y coord for test images\n",
        "  w = np.int8(img_size/3 * np.random.random_sample()+img_size/3);   # random size\n",
        "\n",
        "  # square\n",
        "  for i in range(w):\n",
        "    for j in range(w):\n",
        "      sq_test[y0+i, x0+j, k] = 1;\n",
        "  \n",
        "  # triangle      \n",
        "  for i in range(w):\n",
        "    for j in range(i):\n",
        "      tr_test[y0+i, x0+j, k] = 1;\n",
        "      \n",
        "# Generate images database\n",
        "train_images = [];\n",
        "for i in range(train_size):\n",
        "  train_images.append([sq_train[:,:,i], 0]);\n",
        "  train_images.append([tr_train[:,:,i], 1]);\n",
        "  shuffle(train_images);\n",
        "\n",
        "test_images = [];\n",
        "for i in range(test_size):\n",
        "  test_images.append([sq_test[:,:,i], 0]);\n",
        "  test_images.append([tr_test[:,:,i], 1]);\n",
        "  shuffle(test_images);\n",
        "  \n",
        "\n",
        "# Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,\n",
        "                           input_shape=(img_size, img_size,1)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(2,   activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "tr_img_data = np.array([i[0] for i in train_images]).reshape(-1,img_size,img_size,1)\n",
        "tr_lbl_data = np.array([i[1] for i in train_images])\n",
        "tst_img_data = np.array([i[0] for i in test_images]).reshape(-1,img_size,img_size,1)\n",
        "tst_lbl_data = np.array([i[1] for i in test_images])\n",
        "\n",
        "model.fit(tr_img_data, tr_lbl_data, epochs=10, batch_size=64)\n",
        "model.summary();\n",
        "test_loss, test_accuracy = model.evaluate(tst_img_data, tst_lbl_data, steps=32)\n",
        "      \n",
        "#plt.imshow(sq[:,:,11], cmap=plt.cm.binary)\n",
        "#plt.imshow(tr[:,:,11], cmap=plt.cm.binary)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 1s 618us/sample - loss: 0.3692 - acc: 0.8910\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 0s 316us/sample - loss: 0.0493 - acc: 0.9890\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 0s 313us/sample - loss: 0.0069 - acc: 1.0000\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 0s 321us/sample - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 0s 359us/sample - loss: 6.5937e-04 - acc: 1.0000\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 0s 350us/sample - loss: 4.4319e-04 - acc: 1.0000\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 0s 357us/sample - loss: 3.1639e-04 - acc: 1.0000\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 0s 360us/sample - loss: 2.5906e-04 - acc: 1.0000\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 0s 367us/sample - loss: 2.0433e-04 - acc: 1.0000\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 0s 348us/sample - loss: 1.8543e-04 - acc: 1.0000\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 12, 12, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 6, 6, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               73856     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 92,930\n",
            "Trainable params: 92,930\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 1.0887 - acc: 0.8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq-ZdgGrEM2P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3372c883-f5a7-40a2-d4b2-a4173c552ef5"
      },
      "source": [
        "np.array([1,0]).ndim\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX4JTCQfDK2I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e62cf0d-6d44-4d68-950f-af8b747857a2"
      },
      "source": [
        "tr_lbl_data.ndim\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}